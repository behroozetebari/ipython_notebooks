{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Runs the ti_melt model for a set of drainageIDs and years</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab notebook\n",
    "import datetime as dt\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "from nose.tools import set_trace\n",
    "from charistools.hypsometry import Hypsometry\n",
    "from charistools.meltModels import TriSurfTempIndexMelt\n",
    "from charistools.meltModels import ImshowTriSurfMelt\n",
    "from charistools.meltModels import PlotTriSurfInput\n",
    "from charistools.meltModels import PlotTriSurfMelt\n",
    "from charistools.modelEnv import ModelEnv\n",
    "from charistools.timeSeries import TimeSeries\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "configFile = '/Users/brodzik/ipython_notebooks/charis/snowy_basins_modelEnv_config.ini'\n",
    "myEnv = ModelEnv(tileConfigFile=configFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cat /Users/brodzik/ipython_notebooks/charis/snowy_basins_modelEnv_config.ini\n",
    "#myEnv.tileConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate a list of all OBJECTID basins\n",
    "%cd /Users/brodzik/projects/CHARIS/derived_hypsometries/MODSCAG_GF_v09_fromFile_MERRA_less_ET/\n",
    "majorBasinIDs = ['AM', 'BR','GA_v01', 'IN_v01', 'SY_v01']\n",
    "drainageIDs = []\n",
    "for id in majorBasinIDs:\n",
    "    ids = glob.glob(\"%s_OBJECTID*\" % id)\n",
    "    ids.sort()\n",
    "    drainageIDs = drainageIDs + ids\n",
    "    print(\"There are %d sub-basins for the %s major basin\" % (len(ids), id))\n",
    "\n",
    "len(drainageIDs)\n",
    "drainageIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drainageIDs[62:]\n",
    "drainageIDs = drainageIDs[62:]\n",
    "drainageIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#names = ['Astore', 'DrasNala', 'Gilgit', 'Hunza', 'Kharmong', 'Shigar', 'Shyok', 'Tarbela', 'Zanskar']\n",
    "#names = ['10']\n",
    "#names = ['Tarbela']\n",
    "#drainageIDs = [\"IN_OBJECTID%s\" % name for name in names]\n",
    "drainageIDs = [\"IN_Hunza_at_DainyorBridge\", \"AM_Vakhsh_at_Komsomolabad\", \"GA_Langtang_at_Kyanjin\"]\n",
    "#drainageIDs = [\"GA_Karnali_at_Benighat\", \"GA_Narayani_at_Devghat\", \"GA_SaptaKosi_at_Chatara\"]\n",
    "drainageIDs = [\"IN_Hunza_at_DainyorBridge\", \"GA_SaptaKosi_at_Chatara\"]\n",
    "drainageIDs = [\"AM_Vakhsh_at_Komsomolabad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ablation_method = 'grsize_scag'\n",
    "threshold = 'fromFile'\n",
    "nstrikes = 3\n",
    "\n",
    "years = np.arange(14) + 2001\n",
    "#years = np.arange(1) + 2014\n",
    "\n",
    "#years = np.arange(7) + 2001\n",
    "#DDF_annotation = True\n",
    "#show_rainfall = True\n",
    "#rainfall_col = 'rainfall-et_km3'\n",
    "#show_runoff = True\n",
    "\n",
    "#years = np.arange(7) + 2008\n",
    "DDF_annotation = True\n",
    "show_rainfall = False\n",
    "rainfall_col = 'rainfall-et_km3'\n",
    "show_runoff = False\n",
    "\n",
    "closePlot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drainageIDs, years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(drainageID, year=2001, nstrikes=3, ablation_method='grsize_scag', threshold=205, \n",
    "              model_str=\"8.67_8.67_10.0_17.0\", label='best_model'):\n",
    "    input = myEnv.model_inputs(drainageID=drainageID,\n",
    "                               year=year,\n",
    "                               modice_nstrikes=nstrikes,\n",
    "                               ablation_method=ablation_method,\n",
    "                               threshold=threshold)\n",
    "\n",
    "    (min_snow_ddf, max_snow_ddf, min_ice_ddf, max_ice_ddf) = model_str.split(\"_\")\n",
    "    min_snow_ddf = float(min_snow_ddf)\n",
    "    max_snow_ddf = float(max_snow_ddf)\n",
    "    min_ice_ddf = float(min_ice_ddf)\n",
    "    max_ice_ddf = float(max_ice_ddf)\n",
    "    \n",
    "    (SOLmelt, SOImelt, EGImelt) = TriSurfTempIndexMelt(\n",
    "        input['snow_on_land_by_elevation_filename'],\n",
    "        input['snow_on_ice_by_elevation_filename'],\n",
    "        input['exposed_glacier_ice_by_elevation_filename'],\n",
    "        input['temperature_by_elevation_filename'],\n",
    "        min_snow_ddf=min_snow_ddf,\n",
    "        max_snow_ddf=max_snow_ddf,\n",
    "        min_ice_ddf=min_ice_ddf,\n",
    "        max_ice_ddf=max_ice_ddf)\n",
    "    \n",
    "    SOLmeltfile = input['snow_on_land_by_elevation_filename']\n",
    "    SOImeltfile = input['snow_on_ice_by_elevation_filename']\n",
    "    EGImeltfile = input['exposed_glacier_ice_by_elevation_filename']\n",
    "    SOLmeltfile = SOLmeltfile.replace('area_by_elev.', 'melt_by_elev.' + label + '.')\n",
    "    SOImeltfile = SOImeltfile.replace('area_by_elev.', 'melt_by_elev.' + label + '.')\n",
    "    EGImeltfile = EGImeltfile.replace('area_by_elev.', 'melt_by_elev.' + label + '.')\n",
    "\n",
    "    columns = [float(i) for i in SOLmelt.data.columns]\n",
    "    SOLmelt.data.columns = columns\n",
    "    SOLmelt.data = SOLmelt.data[sort(columns)]\n",
    "\n",
    "    # Temporary fix for SOLmelt.data NaNs\n",
    "    SOLmelt.data = SOLmelt.data.fillna(value=0.)\n",
    "\n",
    "    columns = [float(i) for i in SOImelt.data.columns]\n",
    "    SOImelt.data.columns = columns\n",
    "    SOImelt.data = SOImelt.data[sort(columns)]\n",
    "\n",
    "    columns = [float(i) for i in EGImelt.data.columns]\n",
    "    EGImelt.data.columns = columns\n",
    "    EGImelt.data = EGImelt.data[sort(columns)]\n",
    "\n",
    "    SOLmelt.write(filename=SOLmeltfile, decimal_places=6)\n",
    "    SOImelt.write(filename=SOImeltfile, decimal_places=6)\n",
    "    EGImelt.write(filename=EGImeltfile, decimal_places=6)\n",
    "    \n",
    "    print(\"%s : %d : model=%s\" % (drainageID, year, model_str))\n",
    "    \n",
    "    baseFilename = SOImeltfile\n",
    "    p = re.compile(r'snow_on_ice.+')\n",
    "    baseFilename = p.sub('', baseFilename)\n",
    "    \n",
    "    return(baseFilename, input, model_str, SOLmelt, SOImelt, EGImelt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_isotherm(ax, x, y, color):\n",
    "    orig_ylim = ax.get_ylim()\n",
    "    ax.plot(x, y, c=color)\n",
    "    ax.set_ylim(orig_ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_melt_hyps(drainageID, year, baseFilename, temperatureFilename,\n",
    "                   SOLmelt, SOImelt, EGImelt, label='best_model', closePlot=True):\n",
    "    \n",
    "    year_str = str(year)\n",
    "    fig, axes = plt.subplots(4,1, figsize=(8,10))\n",
    "    \n",
    "    # If SOLmelt is non-empty, but SOImelt and SGImelt are empty,\n",
    "    # then make a copy of the dimensions of SOLmelt that is filled with zeroes\n",
    "    if not SOLmelt.data.empty and SOImelt.data.empty and EGImelt.data.empty:\n",
    "        SOImelt.data = SOLmelt.data.copy()\n",
    "        SOImelt.data[:] = 0.\n",
    "        EGImelt.data = SOLmelt.data.copy()\n",
    "        EGImelt.data[:] = 0.\n",
    "        \n",
    "    ImshowTriSurfMelt(axes[:3], SOLmelt, SOImelt, EGImelt)\n",
    "    \n",
    "    # Fetch the temperature data hypsometry\n",
    "    temperatureHyps = Hypsometry(temperatureFilename)\n",
    "    temperatureHyps.data.replace(to_replace='--', value=0.0, inplace=True)\n",
    "    axes[3] = temperatureHyps.imshow(ax=axes[3], title='Temperature',\n",
    "                                     vmin=-45, vmax=45, cmap='RdGy_r'\n",
    "                                    )\n",
    "    for ax in axes:\n",
    "        ax.set_title(drainageID + \" (\" + year_str + \") \" + ax.get_title())\n",
    "        \n",
    "    # Add a zero-degree isotherm line to each of the melt plots\n",
    "    # Find elevation of zero-degree isotherm\n",
    "    # Default is the highest elevation\n",
    "    zero_isotherm_elevations = np.full(len(temperatureHyps.data.index),\n",
    "                                       float(temperatureHyps.data.columns[-1]))\n",
    "    for i, d in enumerate(temperatureHyps.data.index):\n",
    "        neg_temps = temperatureHyps.data.loc[d][temperatureHyps.data.loc[d] < 0]\n",
    "        if len(neg_temps) > 0:\n",
    "            zero_isotherm_elevations[i] = float(neg_temps.index[0])\n",
    "    \n",
    "                                       \n",
    "        # zero_isotherm_elevations = [\n",
    "        # float(temperatureHyps.data.loc[d][temperatureHyps.data.loc[d] < 0].index[0]) \n",
    "        # for d in temperatureHyps.data.index]\n",
    "    zero_isotherm_x = temperatureHyps.data.index\n",
    "    isotherm_color = (0.8, 0.8, 0.8)\n",
    "    add_isotherm(axes[0], zero_isotherm_x, zero_isotherm_elevations, isotherm_color)\n",
    "    add_isotherm(axes[1], zero_isotherm_x, zero_isotherm_elevations, isotherm_color)\n",
    "    add_isotherm(axes[2], zero_isotherm_x, zero_isotherm_elevations, isotherm_color)\n",
    "    add_isotherm(axes[3], zero_isotherm_x, zero_isotherm_elevations, isotherm_color)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    outfile = baseFilename + label + '.melt_hyps.png'\n",
    "    fig.savefig(outfile)\n",
    "    print(\"Wrote melt_hyps to %s\" % outfile)\n",
    "    if (closePlot):\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_melt_tseries(drainageID, year, baseFilename, input, model_str,\n",
    "                      SOLmelt, SOImelt, EGImelt,\n",
    "                      label='best_model',\n",
    "                      DDF_annotation=True, show_rainfall=False, rainfall_col=None, \n",
    "                      show_runoff=False,\n",
    "                      closePlot=True):\n",
    "    year_str = str(year)\n",
    "    (min_snow_ddf, max_snow_ddf, min_ice_ddf, max_ice_ddf) = model_str.split(\"_\")\n",
    "    min_snow_ddf = float(min_snow_ddf)\n",
    "    max_snow_ddf = float(max_snow_ddf)\n",
    "    min_ice_ddf = float(min_ice_ddf)\n",
    "    max_ice_ddf = float(max_ice_ddf)\n",
    "    \n",
    "    melt_by_doy = (SOLmelt.data_by_doy() +\n",
    "                   SOImelt.data_by_doy() +\n",
    "                   EGImelt.data_by_doy())\n",
    "    total_melt = melt_by_doy.sum()\n",
    "    print(\"total melt = %.2f\" % total_melt)\n",
    "    melt_by_month = melt_by_doy.groupby([pd.TimeGrouper('M')]).sum().to_frame(name='melt')\n",
    "\n",
    "    yyyymm_index = pd.to_datetime(melt_by_month.index.map(lambda x: x.strftime('%Y-%m-15')))\n",
    "    df = pd.DataFrame(data=melt_by_month.values, index=yyyymm_index, columns=['melt'])\n",
    "    df['SOLmelt'] = SOLmelt.data_by_doy().groupby([pd.TimeGrouper('M')]).sum().values\n",
    "    df['SOImelt'] = SOImelt.data_by_doy().groupby([pd.TimeGrouper('M')]).sum().values\n",
    "    df['EGImelt'] = EGImelt.data_by_doy().groupby([pd.TimeGrouper('M')]).sum().values\n",
    "    #print(df)\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(3,1,figsize=(9,9))\n",
    "    left_ax, right_ax = PlotTriSurfInput(\n",
    "        ax[0], \n",
    "        input['snow_on_land_by_elevation_hyps'],\n",
    "        input['snow_on_ice_by_elevation_hyps'],\n",
    "        input['exposed_glacier_ice_by_elevation_hyps'],\n",
    "        input['temperature_by_elevation_hyps'],\n",
    "        temperature_color=(0.7, 0.7, 0.7),\n",
    "        title=\"Inputs for %s (%d)\" % (drainageID, year))\n",
    "    \n",
    "    h, l = left_ax.get_legend_handles_labels()                                       \n",
    "    h1, l1 = right_ax.get_legend_handles_labels()                                    \n",
    "    left_ax.legend(h+h1, l+l1, framealpha=0.5) \n",
    "    #left_ax.legend(framealpha=0.5)\n",
    "    ax[1] = PlotTriSurfMelt(\n",
    "        ax[1], \n",
    "        SOLmelt, \n",
    "        SOImelt, \n",
    "        EGImelt, \n",
    "        title=\"Modelled melt for %s (%d)\" % (drainageID, year))\n",
    "    ax[1].legend(framealpha=0.5)\n",
    "    if DDF_annotation:\n",
    "        ax[1].text(ax[1].get_xlim()[0] + (0.03 * (ax[1].get_xlim()[1] - ax[1].get_xlim()[0])), \n",
    "                   ax[1].get_ylim()[1] * 0.7,\n",
    "                   'snow DDF = %.2f - %.2f $mm/C/day$\\nice DDF = %.2f - %.2f $mm/C/day$' % \n",
    "                   (min_snow_ddf, max_snow_ddf, min_ice_ddf, max_ice_ddf),\n",
    "                   style='italic',\n",
    "                   bbox={'facecolor':'gray', 'alpha':0.1, 'pad':10})\n",
    "    \n",
    "    # Get the line colors used by PlotTriSurfMelt\n",
    "    lines = ax[1].get_lines()\n",
    "    SOIcolor = lines[1].get_color()\n",
    "    EGIcolor = lines[2].get_color()\n",
    "    SOLcolor = lines[3].get_color()\n",
    "\n",
    "    title = \"Melt\"\n",
    "    right_bar_list = ['EGImelt', 'SOImelt', 'SOLmelt']\n",
    "    right_bar_colors = [ EGIcolor, SOIcolor, SOLcolor ]\n",
    "    right_bar_title = \"melt\"\n",
    "    right_bar_sum = df[\"melt\"].sum()\n",
    "    ylim = np.amax(df[\"melt\"])\n",
    "    \n",
    "    # Fetch rainfall and/or runoff, if requested\n",
    "    if show_rainfall:\n",
    "        rainfallFile = myEnv.calibration_filename(type=\"rainfall\", drainageID=drainageID)\n",
    "        rainfall = TimeSeries(rainfallFile)\n",
    "        monthly_rainfall = rainfall.data['rainfall'][year_str + '-01-01':year_str + '-12-01']\n",
    "        \n",
    "        if rainfall_col == \"rainfall-et_km3\":\n",
    "            rainfall_label = \"rainfall-ET\"\n",
    "        elif rainfall_col == \"rainfall\":\n",
    "            rainfall_label = \"rainfall\"\n",
    "        else:\n",
    "            rainfall_label = \"rainfall_unspecified\"\n",
    "            \n",
    "        if 0 < len(monthly_rainfall.index):\n",
    "            df[rainfall_label] = monthly_rainfall.values\n",
    "        else:\n",
    "            df[rainfall_label] = np.nan\n",
    "            \n",
    "        rainfallcolor = 'c'\n",
    "        right_bar_list = [rainfall_label] + right_bar_list\n",
    "        right_bar_colors = [ rainfallcolor ] + right_bar_colors\n",
    "        # The following will ignore any NaNs and just return\n",
    "        # the operation using the non-NaN values:\n",
    "        ylim = np.amax(df[[\"melt\", rainfall_label]].sum(axis=1))\n",
    "        title = rainfall_label + \" + Melt\"\n",
    "        right_bar_title = 'melt + ' + rainfall_label\n",
    "        right_bar_sum = df[[\"melt\", rainfall_label]].sum(axis=1).sum()\n",
    "            \n",
    "    monthly_annotation = '%s = %.2f $km^3$' % (right_bar_title, right_bar_sum)\n",
    "    if show_runoff:\n",
    "        runoffFile = myEnv.calibration_filename(type=\"runoff\", drainageID=drainageID)\n",
    "        runoff = TimeSeries(runoffFile)\n",
    "        monthly_runoff = runoff.data['runoff'][year_str + '-01-01':year_str + '-12-01']\n",
    "        if 0 < len(monthly_runoff.index):\n",
    "            df[\"runoff\"] = monthly_runoff.values\n",
    "            max_runoff = np.amax(df[\"runoff\"])\n",
    "        else:\n",
    "            df[\"runoff\"] = np.nan\n",
    "            max_runoff = 0\n",
    "            \n",
    "        runoffcolor = (0.8, 0.8, 0.8)\n",
    "        ylim = np.amax([ylim, max_runoff])\n",
    "        title = \"Runoff vs. \" + title\n",
    "        df[[\"runoff\"]].plot(ax=ax[2], kind=\"bar\",\n",
    "                            edgecolor=(0.9, 0.9, 0.9),\n",
    "                            color=[runoffcolor])\n",
    "        monthly_annotation = '%s = %.2f $km^3$\\nrunoff = %.2f $km^3$' % (\n",
    "            right_bar_title, right_bar_sum, df[\"runoff\"].sum())\n",
    "    \n",
    "    df[right_bar_list].plot(ax=ax[2], \n",
    "                            stacked=True, kind=\"bar\", \n",
    "                            position=0.,\n",
    "                            edgecolor=(0.9, 0.9, 0.9),\n",
    "                            color=right_bar_colors)\n",
    "    ax[2].set_title(\"Monthly \" + title)\n",
    "    ax[2].set_ylabel('Volume (' + r'$km^3$' + ')') \n",
    "    ax[2].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    for container in ax[2].containers:\n",
    "        plt.setp(container, width=0.25)\n",
    "    ax[2].set_ylim([0, 1.1 * ylim])\n",
    "    ax[2].text(ax[2].get_xlim()[0] + (0.03 * (ax[2].get_xlim()[1] - ax[2].get_xlim()[0])),\n",
    "               ax[2].get_ylim()[1] * 0.7,\n",
    "               monthly_annotation,\n",
    "               style='italic',\n",
    "               bbox={'facecolor':'gray', 'alpha':0.1, 'pad':10})\n",
    "    handles, labels = ax[2].get_legend_handles_labels()\n",
    "    ax[2].legend(reversed(handles), reversed(labels))\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    outfile = baseFilename + label + '.melt_tseries.png'\n",
    "    fig.savefig(outfile)\n",
    "    print(\"Wrote melt_tseries to %s\" % outfile)\n",
    "    if (closePlot):\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "drainageIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for drainageID in drainageIDs:\n",
    "    majorID = drainageID[:2]\n",
    "    if majorID == \"IN\":\n",
    "        model_str = \"8.67_8.67_28.89_28.89\"\n",
    "        label = \"best_Hunza_model\"\n",
    "    elif majorID == \"AM\" or majorID == \"SY\":\n",
    "        model_str = \"2.5_4.67_21.78_24.44\"\n",
    "        label = \"best_Vakhsh_model\"\n",
    "    elif majorID == \"GA\" or majorID == \"BR\":\n",
    "        model_str = \"2.44_2.44_8.78_8.78\"\n",
    "        label = \"best_SaptaKosi_model\"\n",
    "    #if drainageID == \"IN_Hunza_at_DainyorBridge\":\n",
    "    #    model_str = \"8.67_8.67_28.89_28.89\"\n",
    "    #    label = \"best_Hunza_model\"        \n",
    "    #elif drainageID == \"AM_Vakhsh_at_Komsomolabad\":\n",
    "    #    model_str = \"2.5_4.67_21.78_24.44\"\n",
    "    #    label = \"best_Vakhsh_model\"\n",
    "    #elif drainageID == \"GA_SaptaKosi_at_Chatara\":\n",
    "    #    model_str = \"2.44_2.44_8.78_8.78\"\n",
    "    #    label = \"best_SaptaKosi_model\"\n",
    "    else:\n",
    "        print(\"Skipping drainageID=%s, unknown majorID=%s\" % (drainageID, majorID))\n",
    "        #print(\"Skipping drainageID=%s, unknown\" % (drainageID))\n",
    "        continue\n",
    "    print(\"drainageID=%s, majorID=%s, model=%s, label=%s\" % (\n",
    "        drainageID, majorID, model_str, label))\n",
    "    #print(\"drainageID=%s, model=%s, label=%s\" % (\n",
    "        #    drainageID, model_str, label))\n",
    "        \n",
    "    for year in years:      \n",
    "        (baseFilename, input, model_str, SOLmelt, SOImelt, EGImelt) = run_model(\n",
    "            drainageID=drainageID, year=year, nstrikes=nstrikes,\n",
    "            ablation_method=ablation_method, threshold=threshold,\n",
    "            model_str=model_str, label=label)\n",
    "        show_melt_hyps(drainageID, year, baseFilename, input['temperature_by_elevation_filename'],\n",
    "                       SOLmelt, SOImelt, EGImelt, label=label, closePlot=closePlot)\n",
    "        show_melt_tseries(drainageID, year, baseFilename, input, model_str, \n",
    "                          SOLmelt, SOImelt, EGImelt, label=label,\n",
    "                          DDF_annotation=DDF_annotation, \n",
    "                          show_rainfall=show_rainfall,\n",
    "                          rainfall_col=rainfall_col,\n",
    "                          show_runoff=show_runoff,\n",
    "                          closePlot=closePlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyps = Hypsometry(filename=\"/Users/brodzik/projects/CHARIS/derived_hypsometries/modscag_gf_grsize_scag/IN_OBJECTID10/IN_OBJECTID10.2001.0100m.ERA_Interim_downscale_uncorrected_tsurf.v0.2_by_elev.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hyps.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
