{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab notebook\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def move_header_to_top(filename, verbose=False):\n",
    "    # Read the whole file\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find the header and its position\n",
    "    re_header = re.compile(r'DRAINAGE')\n",
    "    header_pos = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if re_header.match(line):\n",
    "            print(\"Found header at position=%d\" % i)\n",
    "            header_pos = i\n",
    "            header = line\n",
    "            break\n",
    "            \n",
    "    # Delete the header from its original position\n",
    "    # And insert it at the beginnin\n",
    "    if header_pos > 0:\n",
    "        del lines[header_pos]\n",
    "        lines.insert(0, header)\n",
    "        \n",
    "    # Write out the new file\n",
    "    f = open(filename, 'w')\n",
    "    for line in lines:\n",
    "        f.write(line)\n",
    "    f.close\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"%s: Moved header to top of file.\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_and_remove_dup_headers(outfilename, filenames):\n",
    "    \n",
    "    outFile = open(outfilename, 'w')\n",
    "    \n",
    "    for i, filename in enumerate(filenames):\n",
    "\n",
    "        with open(filename) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Find the header and its position\n",
    "        re_header = re.compile(r'DRAINAGE')\n",
    "        header_pos = 0\n",
    "        for j, line in enumerate(lines):\n",
    "            if re_header.match(line):\n",
    "                header_pos = j\n",
    "                header = line\n",
    "                break\n",
    "                    \n",
    "        # Delete the header from its original position\n",
    "        print(\"%s: Deleting header at position=%d\" % (filename, header_pos))\n",
    "        del lines[header_pos]\n",
    "\n",
    "        # Insert the header back at the beginning of the first file only\n",
    "        if i == 0:\n",
    "            print(\"%s: Writing header to top of file\" % filename)\n",
    "            lines.insert(0, header)\n",
    "        \n",
    "        for line in lines:\n",
    "            outFile.write(line)\n",
    "            \n",
    "    outFile.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd /Users/brodzik/charis/calibration_stats/modscag_v09_3strikes\n",
    "%ls\n",
    "filename = 'AM_Vakhsh_calibration.out'\n",
    "#filename = 'IN_Hunza_calibration.out'\n",
    "#filename = 'GA_Narayani_calibration-1511446-1.out'\n",
    "#filename = 'GA_SaptaKosi_calibration-1511447-1.out'\n",
    "#filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "move_header_to_top(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_best_model(filename, verbose=False):\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Finding best model from: %s\" % filename, file=sys.stdout)\n",
    "        \n",
    "    # Read the calibration stats and filter for only the columns we plan to use\n",
    "    df = pd.read_table(filename, sep='\\s+')\n",
    "    subdf = df[['DRAINAGEID','YYYY',\n",
    "                'min_snow_ddf','max_snow_ddf','min_ice_ddf','max_ice_ddf',\n",
    "                'Monthly_rmse_km3','Annual_voldiff_pcent']]\n",
    "    \n",
    "    # Make a new column with DDFs concatenated into a model string\n",
    "    # (when multiple years are used for calibrations there will be multiple\n",
    "    # rows with the same model string)\n",
    "    subdf.loc[:,\"model\"] = (\n",
    "        subdf[\"min_snow_ddf\"].map(str) + \"_\" + \n",
    "        subdf[\"max_snow_ddf\"].map(str) + \"_\" +\n",
    "        subdf[\"min_ice_ddf\"].map(str) + \"_\" +\n",
    "        subdf[\"max_ice_ddf\"].map(str))\n",
    "\n",
    "    # Remove duplicates that may have been produced on multiple \n",
    "    # calibration runs \n",
    "    nrows_before = subdf.shape[0]\n",
    "    dups = subdf.duplicated(keep='first')\n",
    "    subdf = subdf[~dups]\n",
    "    if verbose:\n",
    "        print(\"\\nNumber of duplicate rows removed=%d\" % (nrows_before - subdf.shape[0]))\n",
    "        \n",
    "    # Calculate average volDiff and RMSE by modelid (over multiple years)\n",
    "    # Collect the averaged stats into a new DataFrame\n",
    "    mean_vol_diff = subdf.groupby(['model']).mean()['Annual_voldiff_pcent']\n",
    "    mean_rmse = subdf.groupby(['model']).mean()['Monthly_rmse_km3']\n",
    "    stats_df = mean_rmse.to_frame()\n",
    "    stats_df['Annual_voldiff_pcent'] = mean_vol_diff\n",
    "    \n",
    "    # Now, normalize the two variables so they range from 0.0 to 1.0\n",
    "    # Note that Annual voldiff is signed, and we are looking for \n",
    "    # voldiff close to zero (on either side of zero).\n",
    "    # This should map 0. voldiff to 0. and max(|min_vol_diff|,|max_vol_diff|) to 1.0\n",
    "    # and min_rmse to 0. and max_rmse to 1.0\n",
    "    stats_df['Abs_voldiff'] = np.abs(stats_df['Annual_voldiff_pcent'])\n",
    "    biggest_vol_diff = np.max(stats_df['Abs_voldiff'])\n",
    "    \n",
    "    min_rmse = np.min(stats_df['Monthly_rmse_km3'])\n",
    "    max_rmse = np.max(stats_df['Monthly_rmse_km3'])\n",
    "\n",
    "    stats_df['z_Vol_Diff'] = stats_df['Abs_voldiff'] / biggest_vol_diff\n",
    "    stats_df['z_RMSE'] = (\n",
    "        (stats_df['Monthly_rmse_km3'] - min_rmse) / (max_rmse - min_rmse))\n",
    "    stats_df['z'] = stats_df['z_Vol_Diff'] + stats_df['z_RMSE']\n",
    "    \n",
    "    # Now calculate the combined statistic (z_vol_diff + z_rmse) and find the minimum:\n",
    "    if verbose:\n",
    "        print(\"\\nStatistics ranges in this file:\")\n",
    "        print(stats_df.describe().loc[['max','min'],\n",
    "                                      ['Monthly_rmse_km3','Annual_voldiff_pcent','z_Vol_Diff', 'z_RMSE']])\n",
    "\n",
    "    stats_df.sort_values(by=['z'], ascending=True, inplace=True)\n",
    "    \n",
    "    # Summarize results\n",
    "    if verbose:\n",
    "        print(\"\\nDDF ranges included in this file:\")\n",
    "        print(subdf.describe().loc[['max','min'],['min_snow_ddf','max_snow_ddf','min_ice_ddf','max_ice_ddf']])\n",
    "    \n",
    "    # Convert index to a set to get the unique values\n",
    "    # and dump the stats for the model that minimizes z\n",
    "    uniq_models = set(stats_df.index)\n",
    "    if verbose:\n",
    "        print()\n",
    "        print(stats_df.iloc[0])\n",
    "        print(\"\\nNumber of models considered: %d\" % len(uniq_models))\n",
    "        print(\"\\nBest model is %s\" % stats_df.index[0])\n",
    "        \n",
    "    return(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stats_df = find_best_model(filename, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "stats_df['z'][:400].plot(ax=ax)\n",
    "stats_df['z_Vol_Diff'][:400].plot(ax=ax)\n",
    "stats_df['z_RMSE'][:400].plot(ax=ax)\n",
    "ax.legend(loc='best')\n",
    "ax.set_title('Best calibration stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
