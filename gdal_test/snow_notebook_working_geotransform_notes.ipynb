{
 "metadata": {
  "name": "",
  "signature": "sha256:410868df8b0993105095de57a531b9940806dc5fc1613a1a8b932bda94452df4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Adding projection and geotransform metadata to netcdf file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook builds on the ideas that Bryce Nordgren posted to\n",
      "\n",
      "http://nbviewer.ipython.org/gist/bnordgren/47eee80aae57deb303a0\n",
      "\n",
      "Basically, we found that Bryce's changes were still not sufficient to produce the gdalinfo metadata we expected to see, nor to geolocate the geotiff file he produced using ArcGIS.\n",
      "\n",
      "Like Bryce, I am working with this file:\n",
      "\n",
      "ftp://sidads.colorado.edu/pub/DATASETS/nsidc0531_MEASURES_nhsnow_weekly100/2003/nhtsw100e2_20030107_20030113.nc\n",
      "\n",
      "N.B. Bryce observes that this file is \"supposed to be in EASE-Grid 2.0 format.\"  To begin I would like to clarify that EASE-Grid 2.0 is not a file format.  It is a projection definition.  Gridded data in EASE-Grid 2.0 can be stored in any file format, including flat binary, HDF, netCDF and geoTIFF.  There are three EASE-Grid 2.0 projections, which are all in the equal area family: the Lambert Azimuthal North and South and the global cylindrical equal-area projection (with true latitude at +/- 30 degrees).\n",
      "\n",
      "Our tests with gdal utilities, ENVI (5.2) and ArcMap (v10) indicate that the following alterations to the original .nc file will enable correct geolocation in these tools.  We believe that the files need:\n",
      "\n",
      "<ol>\n",
      "<li> row and column coordinate variables (possibly reversed from what Bryce included, see below for details)\n",
      "<li> coordinate system spatial reference metadata, and\n",
      "<li> geotransform metadata\n",
      "</ol>\n",
      "\n",
      "A very interesting source for future reference, on differences between what I saw in epsg wkt and esri/gdal/ogc wkt:\n",
      "\n",
      "http://gis.stackexchange.com/questions/129764/how-are-esri-wkt-projections-different-from-ogc-wkt-projections"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First issue: original file produces this from gdalinfo (on merged_snow_cover_extent):\n",
      "Warning 1: dimension #2 (cols) is not a Longitude/X dimension.\n",
      "Warning 1: dimension #1 (rows) is not a Latitude/Y dimension.\n",
      "and output Coordinate system is undefined,\n",
      "there is no origin/pixel size,\n",
      "and corner points are wrong:\n",
      "Corner Coordinates:\n",
      "Upper Left  (    0.0,    0.0)\n",
      "Lower Left  (    0.0,  180.0)\n",
      "Upper Right (  180.0,    0.0)\n",
      "Lower Right (  180.0,  180.0)\n",
      "Center      (   90.0,   90.0)\n",
      "\n",
      "1) When I added my rows and cols variables, I made them int16, which was too small for the meters range.\n",
      "This eliminated the warnings from gdalinfo,\n",
      "and now the output Coordinate system is defined (correctly, I think)\n",
      "and there are now rows and cols dimension variables,\n",
      "but there is no origin/pixel size and\n",
      "the Corner Coordinates are still\n",
      "Corner Coordinates:\n",
      "Upper Left  (    0.0,    0.0)\n",
      "Lower Left  (    0.0,  180.0)\n",
      "Upper Right (  180.0,    0.0)\n",
      "Lower Right (  180.0,  180.0)\n",
      "Center      (   90.0,   90.0)\n",
      "Further, the dimension variables contain junk ( think because python is casting the floats or doubles into int16s):\n",
      "test = d.variables['rows'][::]\n",
      "print test\n",
      "[ 28432  -2640  31824    752 -30320   4144 -26928   7536 -23536  10928\n",
      " -20144  14320...\n",
      "\n",
      "2) Next try using a sufficiently large float32 for the dimension variables.\n",
      "This eliminated the warnings from gdalinfo,\n",
      "and now the output Coordinate system is defined (correctly, I think),\n",
      "along with the correct origin/pixel size,\n",
      "and there are now rows and cols dimension variables,\n",
      "the Corner Coordinates are correct:\n",
      "> Upper Left  (-9000000.000, 9000000.000) \n",
      "> Lower Left  (-9000000.000,-9000000.000) \n",
      "> Upper Right ( 9000000.000, 9000000.000) \n",
      "> Lower Right ( 9000000.000,-9000000.000) \n",
      "> Center      (   0.0000000,   0.0000000) \n",
      "\n",
      "Further, the dimension variables contain what I set (which goes from bottom-up):\n",
      "test = d.variables['rows'][::]\n",
      "print test\n",
      "[-8950000. -8850000. -8750000. -8650000. -8550000. -8450000. -8350000.\n",
      " -8250000. -8150000...\n",
      " \n",
      "However, \n",
      "\n",
      "gdal_translate -of GTiff -b 1 NETCDF:nhtsw100e2_20030107_20030113.coordvar.nc:merged_snow_cover_extent out.tif\n",
      "complains with this:\n",
      "Input file size is 180, 180\n",
      "0ERROR 1: nBlockYSize = 180, only 1 supported when reading bottom-up dataset\n",
      "ERROR 1: NETCDF:nhtsw100e2_20030107_20030113.coordvar.nc:merged_snow_cover_extent, band 1: IReadBlock failed at X offset 0, Y offset 0\n",
      "ERROR 1: GetBlockRef failed at X block offset 0, Y block offset 0\n",
      "\n",
      "3) So I tried defining the rows to start with the largest numbers first (the UL corner)\n",
      "Now the gdalinfo matches what I got in 2), and there is no error from gdal_translate.\n",
      "Doing gdalinfo on the .nc and .tif files returns different things:\n",
      "\n",
      "vagrant@vsnowyski:~/ipynb$ diff gdalinfo.coordvar_yUL.nc.txt gdalinfo.coordvar_yUL.tif.txt \n",
      "1,2c1,2\n",
      "< Driver: netCDF/Network Common Data Format\n",
      "< Files: nhtsw100e2_20030107_20030113.coordvar_yUL.nc\n",
      "---\n",
      "> Driver: GTiff/GeoTIFF\n",
      "> Files: snowcover.coordvar_yUL.tif\n",
      "10d9\n",
      "<             TOWGS84[0,0,0,0,0,0,0],\n",
      "12,15c11,12\n",
      "<         PRIMEM[\"Greenwich\",0,\n",
      "<             AUTHORITY[\"EPSG\",\"8901\"]],\n",
      "<         UNIT[\"degree\",0.0174532925199433,\n",
      "<             AUTHORITY[\"EPSG\",\"9108\"]],\n",
      "---\n",
      ">         PRIMEM[\"Greenwich\",0],\n",
      ">         UNIT[\"degree\",0.0174532925199433],\n",
      "21c18,20\n",
      "<     PARAMETER[\"false_northing\",0]]\n",
      "---\n",
      ">     PARAMETER[\"false_northing\",0],\n",
      ">     UNIT[\"metre\",1,\n",
      ">         AUTHORITY[\"EPSG\",\"9001\"]]]\n",
      "24a24\n",
      ">   AREA_OR_POINT=Area\n",
      "85,94c85,86\n",
      "< Geolocation:\n",
      "<   LINE_OFFSET=0\n",
      "<   LINE_STEP=1\n",
      "<   PIXEL_OFFSET=0\n",
      "<   PIXEL_STEP=1\n",
      "<   SRS=GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9108\"]],AUTHORITY[\"EPSG\",\"4326\"]]\n",
      "<   X_BAND=1\n",
      "<   X_DATASET=NETCDF:\"nhtsw100e2_20030107_20030113.coordvar_yUL.nc\":longitude\n",
      "<   Y_BAND=1\n",
      "<   Y_DATASET=NETCDF:\"nhtsw100e2_20030107_20030113.coordvar_yUL.nc\":latitude\n",
      "---\n",
      "> Image Structure Metadata:\n",
      ">   INTERLEAVE=BAND\n",
      "101c93\n",
      "< Band 1 Block=180x180 Type=Byte, ColorInterp=Undefined\n",
      "---\n",
      "> Band 1 Block=180x45 Type=Byte, ColorInterp=Gray\n",
      "vagrant@vsnowyski:~/ipynb$ cp snowcover.coordvar_yUL.tif /projects/PMESDR/vagrant/brodzik/gdal_test/\n",
      "\n",
      "of which the only thing that bothers me is this in the tif:\n",
      "\n",
      "> Band 1 Block=180x45 Type=Byte, ColorInterp=Gray\n",
      "\n",
      "I would expect it to be 180x180.\n",
      "\n",
      "However, ArcGIS reads it, fine.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import mpl_toolkits.basemap.pyproj as pyproj\n",
      "import netCDF4 as nc\n",
      "import os\n",
      "import numpy as np\n",
      "from mpl_toolkits.basemap import Basemap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I open the file for writing, and examine the coordinate system information.  I can see the information about the Northern EASE-Grid 2.0, which looks fine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "RuntimeError",
       "evalue": "NetCDF: Not a valid ID",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-78-ef507f445a30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/opt/miniconda/lib/python2.7/site-packages/netCDF4.so\u001b[0m in \u001b[0;36mnetCDF4.Dataset.close (netCDF4.c:23693)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;31mRuntimeError\u001b[0m: NetCDF: Not a valid ID"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.chdir(\"/home/vagrant/ipynb/\")\n",
      "d = nc.Dataset('nhtsw100e2_20030107_20030113.nc', 'r+')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'netCDF4.Dataset'>\n",
        "root group (NETCDF4_CLASSIC data model, file format UNDEFINED):\n",
        "    Conventions: CF-1.6\n",
        "    Metadata_Conventions: CF-1.6, Unidata Dataset Discovery v1.0, GDS v2.0\n",
        "    standard_name_vocabulary: CF Standard Name Table (v22, 12 February 2013)\n",
        "    id: nhtsw100e2_20030107_20030113.nc\n",
        "    naming_authority: gov.nasa.eosdis\n",
        "    reference: http://dx.doi.org/10.5067/MEASURES/CRYOSPHERE/nsidc-0531.001\n",
        "    metadata_link: http://nsidc.org/api/metadata?id=nsidc-0531\n",
        "    title: MEaSUREs Northern Hemisphere Terrestrial Snow Cover Extent Weekly 100km EASE-Grid 2.0\n",
        "    product_version: v01r00\n",
        "    summary: This NASA MEaSUREs Earth System Data Record (ESDR) merges daily Northern Hemisphere snow cover extents over land derived from two independently produced sources.  Variables include snow cover extent from the weekly NOAA/NCDC Northern Hemisphere Snow Cover Extent Climate Data Record (NH SCE CDR) and a gap-filled snow extent product derived from the Special Sensor Microwave/Imager (SSMI) and Special Sensor Microwave Imager/Sounder (SSMIS).  The NSIDC Land-Ocean-Coast-Ice (LOCI) mask derived from BU-MODIS land cover data is consistently applied to each variable.  Data are in a Northern Hemisphere equal area projection at 100 km resolution, and are contained in weekly netCDF files spanning from October 4, 1966 to December 31, 2012.\n",
        "    keywords: EARTH SCIENCE > CRYOSPHERE > SNOW/ICE > SNOW COVER, EARTH SCIENCE > TERRESTRIAL HYDROSPHERE > SNOW/ICE > SNOW COVER\n",
        "    keywords_vocabulary: NASA Global Change Master Directory (GCMD) Earth Science Keywords, Version 8.0\n",
        "    platform: NOAA POES (Polar Orbiting Environmental Satellites), DMSP (Defense Meteorological Satellite Program), GOES (Geostationary Operational Environmental Satellite), METEOSAT, GMS (Japan Geostationary Meteorological Satellite), METOP, TERRA > Earth Observing System TERRA (AM-1), AQUA > Earth Observing System AQUA\n",
        "    sensor: VISSR > Visible and Infrared Spin Scan Radiometer, VAS > VISSR Atmospheric Sounder, MODIS > Moderate-Resolution Imaging Spectroradiometer, AMSU-B > Advanced Microwave Sounding Unit-B, AMSR-E > Advanced Microwave Scanning Radiometer-EOS, SSMI > Special Sensor Microwave/Imager, SSMIS > Special Sensor Microwave Imager/Sounder, VIIRS > Visible-Infrared Imager-Radiometer Suite\n",
        "    cdm_data_type: Grid\n",
        "    source: ftp://data.ncdc.noaa.gov/cdr/snowcover/, ftp://sidads.colorado.edu/pub/DATASETS/nsidc0001_polar_stereo_tbs/\n",
        "    date_created: 2014-09-09T16:19:30Z\n",
        "    institution: Center for Environmental Prediction, Rutgers University\n",
        "    geospatial_lat_units: degrees_north\n",
        "    geospatial_lon_units: degrees_east\n",
        "    geospatial_lat_min: 0\n",
        "    geospatial_lat_max: 90\n",
        "    geospatial_lon_min: -180\n",
        "    geospatial_lon_max: 180\n",
        "    spatial_resolution: 100 km\n",
        "    time_coverage_start: 2003-01-07\n",
        "    time_coverage_end: 2003-01-13\n",
        "    license: No restrictions on access or use\n",
        "    dimensions(sizes): time(1), rows(180), cols(180)\n",
        "    variables(dimensions): int32 \u001b[4mtime\u001b[0m(time), float32 \u001b[4mlatitude\u001b[0m(rows,cols), float32 \u001b[4mlongitude\u001b[0m(rows,cols), int8 \u001b[4mmerged_snow_cover_extent\u001b[0m(time,rows,cols), int8 \u001b[4mweekly_climate_data_record_snow_cover_extent\u001b[0m(time,rows,cols), int8 \u001b[4mpassive_microwave_gap_filled_snow_cover_extent\u001b[0m(time,rows,cols), |S1 \u001b[4mcoord_system\u001b[0m()\n",
        "    groups: \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = d.variables['rows'][::]\n",
      "print test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 8950000.  8850000.  8750000.  8650000.  8550000.  8450000.  8350000.\n",
        "  8250000.  8150000.  8050000.  7950000.  7850000.  7750000.  7650000.\n",
        "  7550000.  7450000.  7350000.  7250000.  7150000.  7050000.  6950000.\n",
        "  6850000.  6750000.  6650000.  6550000.  6450000.  6350000.  6250000.\n",
        "  6150000.  6050000.  5950000.  5850000.  5750000.  5650000.  5550000.\n",
        "  5450000.  5350000.  5250000.  5150000.  5050000.  4950000.  4850000.\n",
        "  4750000.  4650000.  4550000.  4450000.  4350000.  4250000.  4150000.\n",
        "  4050000.  3950000.  3850000.  3750000.  3650000.  3550000.  3450000.\n",
        "  3350000.  3250000.  3150000.  3050000.  2950000.  2850000.  2750000.\n",
        "  2650000.  2550000.  2450000.  2350000.  2250000.  2150000.  2050000.\n",
        "  1950000.  1850000.  1750000.  1650000.  1550000.  1450000.  1350000.\n",
        "  1250000.  1150000.  1050000.   950000.   850000.   750000.   650000.\n",
        "   550000.   450000.   350000.   250000.   150000.    50000.   -50000.\n",
        "  -150000.  -250000.  -350000.  -450000.  -550000.  -650000.  -750000.\n",
        "  -850000.  -950000. -1050000. -1150000. -1250000. -1350000. -1450000.\n",
        " -1550000. -1650000. -1750000. -1850000. -1950000. -2050000. -2150000.\n",
        " -2250000. -2350000. -2450000. -2550000. -2650000. -2750000. -2850000.\n",
        " -2950000. -3050000. -3150000. -3250000. -3350000. -3450000. -3550000.\n",
        " -3650000. -3750000. -3850000. -3950000. -4050000. -4150000. -4250000.\n",
        " -4350000. -4450000. -4550000. -4650000. -4750000. -4850000. -4950000.\n",
        " -5050000. -5150000. -5250000. -5350000. -5450000. -5550000. -5650000.\n",
        " -5750000. -5850000. -5950000. -6050000. -6150000. -6250000. -6350000.\n",
        " -6450000. -6550000. -6650000. -6750000. -6850000. -6950000. -7050000.\n",
        " -7150000. -7250000. -7350000. -7450000. -7550000. -7650000. -7750000.\n",
        " -7850000. -7950000. -8050000. -8150000. -8250000. -8350000. -8450000.\n",
        " -8550000. -8650000. -8750000. -8850000. -8950000.]\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coords = d.variables['coord_system']\n",
      "print coords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'netCDF4.Variable'>\n",
        "|S1 coord_system()\n",
        "    comment: EASE-Grid-2.0 projection definition documention: http://nsidc.org/data/ease/ease_grid2.html, NSIDC mapx grid parameter definition file: EASE2_N100km.gpd, grid_id: EASE2_N100km\n",
        "    grid_mapping_name: lambert_azimuthal_equal_area\n",
        "    longitude_of_projection_origin: 0.0\n",
        "    latitude_of_projection_origin: 90.0\n",
        "    false_easting: 0.0\n",
        "    false_northing: 0.0\n",
        "    scale_factor_at_projection_origin: 25\n",
        "    semimajor_axis: 6.37814e+06\n",
        "    semiminor_axis: 6.35675e+06\n",
        "    inverse_flattening: 298.257\n",
        "unlimited dimensions: \n",
        "current shape = ()\n",
        "filling on, default _FillValue of \u0000 used\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I believe was correct in stating that his problem was that row and column coordinate variables were missing.  Bryce outlined an empirical method for determining the values needed, but I know a couple of things about this projection, namely that the origin of the project is the North Pole, which is centered at the intersection of the 4 center cells.  The file level metadata is telling me that the resolution is 100 km.  I believe it is customary in projection mathematics to assume a left-handed Cartesian coordinate system positioned at the origin, with X increasing to the right and Y increasing up.  \n",
      "\n",
      "In order to set the row and column coordinate values to the centers of each cell, I calculate the values for each axis by multiplying each cell index by the map scale (100000. m).  The offset of 50000 m positions each value at the center of each cell."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "map_scale_x_meters = 100000.\n",
      "ncols = len(d.dimensions['cols'])\n",
      "x_meters = ( np.arange(ncols) - (ncols/2) ) * map_scale_x_meters + (map_scale_x_meters/2)\n",
      "print x_meters\n",
      "print type(x_meters[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-8950000. -8850000. -8750000. -8650000. -8550000. -8450000. -8350000.\n",
        " -8250000. -8150000. -8050000. -7950000. -7850000. -7750000. -7650000.\n",
        " -7550000. -7450000. -7350000. -7250000. -7150000. -7050000. -6950000.\n",
        " -6850000. -6750000. -6650000. -6550000. -6450000. -6350000. -6250000.\n",
        " -6150000. -6050000. -5950000. -5850000. -5750000. -5650000. -5550000.\n",
        " -5450000. -5350000. -5250000. -5150000. -5050000. -4950000. -4850000.\n",
        " -4750000. -4650000. -4550000. -4450000. -4350000. -4250000. -4150000.\n",
        " -4050000. -3950000. -3850000. -3750000. -3650000. -3550000. -3450000.\n",
        " -3350000. -3250000. -3150000. -3050000. -2950000. -2850000. -2750000.\n",
        " -2650000. -2550000. -2450000. -2350000. -2250000. -2150000. -2050000.\n",
        " -1950000. -1850000. -1750000. -1650000. -1550000. -1450000. -1350000.\n",
        " -1250000. -1150000. -1050000.  -950000.  -850000.  -750000.  -650000.\n",
        "  -550000.  -450000.  -350000.  -250000.  -150000.   -50000.    50000.\n",
        "   150000.   250000.   350000.   450000.   550000.   650000.   750000.\n",
        "   850000.   950000.  1050000.  1150000.  1250000.  1350000.  1450000.\n",
        "  1550000.  1650000.  1750000.  1850000.  1950000.  2050000.  2150000.\n",
        "  2250000.  2350000.  2450000.  2550000.  2650000.  2750000.  2850000.\n",
        "  2950000.  3050000.  3150000.  3250000.  3350000.  3450000.  3550000.\n",
        "  3650000.  3750000.  3850000.  3950000.  4050000.  4150000.  4250000.\n",
        "  4350000.  4450000.  4550000.  4650000.  4750000.  4850000.  4950000.\n",
        "  5050000.  5150000.  5250000.  5350000.  5450000.  5550000.  5650000.\n",
        "  5750000.  5850000.  5950000.  6050000.  6150000.  6250000.  6350000.\n",
        "  6450000.  6550000.  6650000.  6750000.  6850000.  6950000.  7050000.\n",
        "  7150000.  7250000.  7350000.  7450000.  7550000.  7650000.  7750000.\n",
        "  7850000.  7950000.  8050000.  8150000.  8250000.  8350000.  8450000.\n",
        "  8550000.  8650000.  8750000.  8850000.  8950000.]\n",
        "<type 'numpy.float64'>\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I could calculate the y_meters similarly, but I know that this projection is azimuthal and symmetric, \n",
      "so I can just set y_meters values to be the same as x_meters, but it turns out that the order of the\n",
      "values is important.\n",
      "\n",
      "At first I did the same thing Bryce did, which was to order the x values from left to right and\n",
      "the y values from top to bottom.  This would mean:\n",
      "\n",
      "y_meters = x_meters[::-1]\n",
      "\n",
      "However as Bryce points out, this requires that the gdal utilities assume a default orientation \n",
      "for the gridded data that is flipped from top to bottom.  This would require that gdal_translate\n",
      "be called with \"--config GDAL_NETCDF_BOTTOMUP NO\".\n",
      "\n",
      "I experimented with this and found that setting y_meters with the smallest values first means that\n",
      "I can call gdal utilities without this config switch.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_meters = x_meters.astype(np.float32)\n",
      "print x_meters\n",
      "print type(x_meters[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-8950000. -8850000. -8750000. -8650000. -8550000. -8450000. -8350000.\n",
        " -8250000. -8150000. -8050000. -7950000. -7850000. -7750000. -7650000.\n",
        " -7550000. -7450000. -7350000. -7250000. -7150000. -7050000. -6950000.\n",
        " -6850000. -6750000. -6650000. -6550000. -6450000. -6350000. -6250000.\n",
        " -6150000. -6050000. -5950000. -5850000. -5750000. -5650000. -5550000.\n",
        " -5450000. -5350000. -5250000. -5150000. -5050000. -4950000. -4850000.\n",
        " -4750000. -4650000. -4550000. -4450000. -4350000. -4250000. -4150000.\n",
        " -4050000. -3950000. -3850000. -3750000. -3650000. -3550000. -3450000.\n",
        " -3350000. -3250000. -3150000. -3050000. -2950000. -2850000. -2750000.\n",
        " -2650000. -2550000. -2450000. -2350000. -2250000. -2150000. -2050000.\n",
        " -1950000. -1850000. -1750000. -1650000. -1550000. -1450000. -1350000.\n",
        " -1250000. -1150000. -1050000.  -950000.  -850000.  -750000.  -650000.\n",
        "  -550000.  -450000.  -350000.  -250000.  -150000.   -50000.    50000.\n",
        "   150000.   250000.   350000.   450000.   550000.   650000.   750000.\n",
        "   850000.   950000.  1050000.  1150000.  1250000.  1350000.  1450000.\n",
        "  1550000.  1650000.  1750000.  1850000.  1950000.  2050000.  2150000.\n",
        "  2250000.  2350000.  2450000.  2550000.  2650000.  2750000.  2850000.\n",
        "  2950000.  3050000.  3150000.  3250000.  3350000.  3450000.  3550000.\n",
        "  3650000.  3750000.  3850000.  3950000.  4050000.  4150000.  4250000.\n",
        "  4350000.  4450000.  4550000.  4650000.  4750000.  4850000.  4950000.\n",
        "  5050000.  5150000.  5250000.  5350000.  5450000.  5550000.  5650000.\n",
        "  5750000.  5850000.  5950000.  6050000.  6150000.  6250000.  6350000.\n",
        "  6450000.  6550000.  6650000.  6750000.  6850000.  6950000.  7050000.\n",
        "  7150000.  7250000.  7350000.  7450000.  7550000.  7650000.  7750000.\n",
        "  7850000.  7950000.  8050000.  8150000.  8250000.  8350000.  8450000.\n",
        "  8550000.  8650000.  8750000.  8850000.  8950000.]\n",
        "<type 'numpy.float32'>\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use this order (smallest y coordinates first)\n",
      "# if the data arrays are left alone in the file\n",
      "# doing this means that gdal_translate doesn't have to be called with \n",
      "# \"--config GDAL_NETCDF_BOTTOMUP NO\" to override the gdal drivers\n",
      "#y_meters = x_meters\n",
      "\n",
      "# However, I think the correct way to set up these files for\n",
      "# gdal drivers to interpret them correctly would be to reverse the\n",
      "# actual data arrays by row, and then use this for the\n",
      "# y coordinates:\n",
      "y_meters = x_meters[::-1]\n",
      "\n",
      "# It's not clear to me whether this is a CF issue or a gdal convention."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now I just did the same thing Bryce did to define row and column coordinate variables, \n",
      "with the expected standard_names."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make the rows coordinate variable\n",
      "# note the variable name is the same as the dimension name\n",
      "# the standard_name set to 'projection_y_coordinate'\n",
      "# is needed for gdal to understand the geolocation\n",
      "rows_var = d.createVariable('rows',np.float32, ('rows',))\n",
      "\n",
      "# give it the expected attributes\n",
      "rows_var.standard_name = 'projection_y_coordinate'\n",
      "rows_var.axis          = 'Y'\n",
      "rows_var.units         = 'meters'\n",
      "\n",
      "# write the values to the variable\n",
      "rows_var[:] = y_meters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make the cols coordinate variable similarly\n",
      "cols_var = d.createVariable('cols',np.float32, ('cols',))\n",
      "# give it the expected attributes\n",
      "cols_var.standard_name = 'projection_x_coordinate'\n",
      "cols_var.axis          = 'X'\n",
      "cols_var.units         = 'meters'\n",
      "\n",
      "# write the values to the variable\n",
      "cols_var[:] = x_meters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print d\n",
      "print d.variables['rows'][::]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'netCDF4.Dataset'>\n",
        "root group (NETCDF4_CLASSIC data model, file format UNDEFINED):\n",
        "    Conventions: CF-1.6\n",
        "    Metadata_Conventions: CF-1.6, Unidata Dataset Discovery v1.0, GDS v2.0\n",
        "    standard_name_vocabulary: CF Standard Name Table (v22, 12 February 2013)\n",
        "    id: nhtsw100e2_20030107_20030113.nc\n",
        "    naming_authority: gov.nasa.eosdis\n",
        "    reference: http://dx.doi.org/10.5067/MEASURES/CRYOSPHERE/nsidc-0531.001\n",
        "    metadata_link: http://nsidc.org/api/metadata?id=nsidc-0531\n",
        "    title: MEaSUREs Northern Hemisphere Terrestrial Snow Cover Extent Weekly 100km EASE-Grid 2.0\n",
        "    product_version: v01r00\n",
        "    summary: This NASA MEaSUREs Earth System Data Record (ESDR) merges daily Northern Hemisphere snow cover extents over land derived from two independently produced sources.  Variables include snow cover extent from the weekly NOAA/NCDC Northern Hemisphere Snow Cover Extent Climate Data Record (NH SCE CDR) and a gap-filled snow extent product derived from the Special Sensor Microwave/Imager (SSMI) and Special Sensor Microwave Imager/Sounder (SSMIS).  The NSIDC Land-Ocean-Coast-Ice (LOCI) mask derived from BU-MODIS land cover data is consistently applied to each variable.  Data are in a Northern Hemisphere equal area projection at 100 km resolution, and are contained in weekly netCDF files spanning from October 4, 1966 to December 31, 2012.\n",
        "    keywords: EARTH SCIENCE > CRYOSPHERE > SNOW/ICE > SNOW COVER, EARTH SCIENCE > TERRESTRIAL HYDROSPHERE > SNOW/ICE > SNOW COVER\n",
        "    keywords_vocabulary: NASA Global Change Master Directory (GCMD) Earth Science Keywords, Version 8.0\n",
        "    platform: NOAA POES (Polar Orbiting Environmental Satellites), DMSP (Defense Meteorological Satellite Program), GOES (Geostationary Operational Environmental Satellite), METEOSAT, GMS (Japan Geostationary Meteorological Satellite), METOP, TERRA > Earth Observing System TERRA (AM-1), AQUA > Earth Observing System AQUA\n",
        "    sensor: VISSR > Visible and Infrared Spin Scan Radiometer, VAS > VISSR Atmospheric Sounder, MODIS > Moderate-Resolution Imaging Spectroradiometer, AMSU-B > Advanced Microwave Sounding Unit-B, AMSR-E > Advanced Microwave Scanning Radiometer-EOS, SSMI > Special Sensor Microwave/Imager, SSMIS > Special Sensor Microwave Imager/Sounder, VIIRS > Visible-Infrared Imager-Radiometer Suite\n",
        "    cdm_data_type: Grid\n",
        "    source: ftp://data.ncdc.noaa.gov/cdr/snowcover/, ftp://sidads.colorado.edu/pub/DATASETS/nsidc0001_polar_stereo_tbs/\n",
        "    date_created: 2014-09-09T16:19:30Z\n",
        "    institution: Center for Environmental Prediction, Rutgers University\n",
        "    geospatial_lat_units: degrees_north\n",
        "    geospatial_lon_units: degrees_east\n",
        "    geospatial_lat_min: 0\n",
        "    geospatial_lat_max: 90\n",
        "    geospatial_lon_min: -180\n",
        "    geospatial_lon_max: 180\n",
        "    spatial_resolution: 100 km\n",
        "    time_coverage_start: 2003-01-07\n",
        "    time_coverage_end: 2003-01-13\n",
        "    license: No restrictions on access or use\n",
        "    dimensions(sizes): time(1), rows(180), cols(180)\n",
        "    variables(dimensions): int32 \u001b[4mtime\u001b[0m(time), float32 \u001b[4mlatitude\u001b[0m(rows,cols), float32 \u001b[4mlongitude\u001b[0m(rows,cols), int8 \u001b[4mmerged_snow_cover_extent\u001b[0m(time,rows,cols), int8 \u001b[4mweekly_climate_data_record_snow_cover_extent\u001b[0m(time,rows,cols), int8 \u001b[4mpassive_microwave_gap_filled_snow_cover_extent\u001b[0m(time,rows,cols), |S1 \u001b[4mcoord_system\u001b[0m(), float32 \u001b[4mrows\u001b[0m(rows), float32 \u001b[4mcols\u001b[0m(cols)\n",
        "    groups: \n",
        "\n",
        "[ 8950000.  8850000.  8750000.  8650000.  8550000.  8450000.  8350000.\n",
        "  8250000.  8150000.  8050000.  7950000.  7850000.  7750000.  7650000.\n",
        "  7550000.  7450000.  7350000.  7250000.  7150000.  7050000.  6950000.\n",
        "  6850000.  6750000.  6650000.  6550000.  6450000.  6350000.  6250000.\n",
        "  6150000.  6050000.  5950000.  5850000.  5750000.  5650000.  5550000.\n",
        "  5450000.  5350000.  5250000.  5150000.  5050000.  4950000.  4850000.\n",
        "  4750000.  4650000.  4550000.  4450000.  4350000.  4250000.  4150000.\n",
        "  4050000.  3950000.  3850000.  3750000.  3650000.  3550000.  3450000.\n",
        "  3350000.  3250000.  3150000.  3050000.  2950000.  2850000.  2750000.\n",
        "  2650000.  2550000.  2450000.  2350000.  2250000.  2150000.  2050000.\n",
        "  1950000.  1850000.  1750000.  1650000.  1550000.  1450000.  1350000.\n",
        "  1250000.  1150000.  1050000.   950000.   850000.   750000.   650000.\n",
        "   550000.   450000.   350000.   250000.   150000.    50000.   -50000.\n",
        "  -150000.  -250000.  -350000.  -450000.  -550000.  -650000.  -750000.\n",
        "  -850000.  -950000. -1050000. -1150000. -1250000. -1350000. -1450000.\n",
        " -1550000. -1650000. -1750000. -1850000. -1950000. -2050000. -2150000.\n",
        " -2250000. -2350000. -2450000. -2550000. -2650000. -2750000. -2850000.\n",
        " -2950000. -3050000. -3150000. -3250000. -3350000. -3450000. -3550000.\n",
        " -3650000. -3750000. -3850000. -3950000. -4050000. -4150000. -4250000.\n",
        " -4350000. -4450000. -4550000. -4650000. -4750000. -4850000. -4950000.\n",
        " -5050000. -5150000. -5250000. -5350000. -5450000. -5550000. -5650000.\n",
        " -5750000. -5850000. -5950000. -6050000. -6150000. -6250000. -6350000.\n",
        " -6450000. -6550000. -6650000. -6750000. -6850000. -6950000. -7050000.\n",
        " -7150000. -7250000. -7350000. -7450000. -7550000. -7650000. -7750000.\n",
        " -7850000. -7950000. -8050000. -8150000. -8250000. -8350000. -8450000.\n",
        " -8550000. -8650000. -8750000. -8850000. -8950000.]\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, I found that the coordinate variables still didn't return gdalinfo metadata with \n",
      "the correct corner values, so "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add spatial reference and geotransform to coordinate system\n",
      "# I lifted the following wkt from a geotiff that I created using python gdal tools, where\n",
      "# I specified the projection with the proj.4 string.\n",
      "#coords.spatial_ref = \"PROJCS[\\\"unnamed\\\",GEOGCS[\\\"WGS 84\\\",DATUM[\\\"WGS_1984\\\",SPHEROID[\\\"WGS 84\\\",6378137,298.257223563,AUTHORITY[\\\"EPSG\\\",\\\"7030\\\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\\\"EPSG\\\",\\\"6326\\\"]],PRIMEM[\\\"Greenwich\\\",0,AUTHORITY[\\\"EPSG\\\",\\\"8901\\\"]],UNIT[\\\"degree\\\",0.0174532925199433,AUTHORITY[\\\"EPSG\\\",\\\"9108\\\"]],AUTHORITY[\\\"EPSG\\\",\\\"4326\\\"]],PROJECTION[\\\"Lambert_Azimuthal_Equal_Area\\\"],PARAMETER[\\\"latitude_of_center\\\",90],PARAMETER[\\\"longitude_of_center\\\",0],PARAMETER[\\\"false_easting\\\",0],PARAMETER[\\\"false_northing\\\",0],UNIT[\\\"Meter\\\",1]]\"\n",
      "#coords.spatial_ref = \\\n",
      "#    \"PROJCS[\\\"WGS 84 / NSIDC EASE-Grid 2.0 North\\\",\" \\\n",
      "#    + \"  GEOGCS[\\\"WGS 84\\\",\" \\\n",
      "#    + \"    DATUM[\\\"WGS_1984\\\",\" \\\n",
      "#    + \"      SPHEROID[\\\"WGS 84\\\",6378137,298.257223563,AUTHORITY[\\\"EPSG\\\",\\\"7030\\\"]],\" \\\n",
      "#    + \"      TOWGS84[0,0,0,0,0,0,0],\" \\\n",
      "#    + \"      AUTHORITY[\\\"EPSG\\\",\\\"6326\\\"]],\" \\\n",
      "#    + \"    PRIMEM[\\\"Greenwich\\\",0,AUTHORITY[\\\"EPSG\\\",\\\"8901\\\"]],\" \\\n",
      "#    + \"    UNIT[\\\"degree\\\",0.0174532925199433,AUTHORITY[\\\"EPSG\\\",\\\"9108\\\"]],\" \\\n",
      "#    + \"    AUTHORITY[\\\"EPSG\\\",\\\"4326\\\"]],\" \\\n",
      "#    + \"  PROJECTION[\\\"Lambert_Azimuthal_Equal_Area\\\"],\" \\\n",
      "#    + \"    PARAMETER[\\\"latitude_of_center\\\",90],\" \\\n",
      "#    + \"    PARAMETER[\\\"longitude_of_center\\\",0],\" \\\n",
      "#    + \"    PARAMETER[\\\"false_easting\\\",0],\" \\\n",
      "#    + \"    PARAMETER[\\\"false_northing\\\",0],\" \\\n",
      "#    + \"  UNIT[\\\"Meter\\\",1]]\"\n",
      "# This is the wkt for epsg 6931, taken directly from the epsg-registry.org site.\n",
      "#coords.spatial_ref = \\\n",
      "#    \"PROJCS[\\\"WGS 84 / NSIDC EASE-Grid 2.0 North\\\",\" \\\n",
      "#    + \"  GEOGCS[\\\"WGS 84\\\",\" \\\n",
      "#    + \"    DATUM[\\\"WGS_1984\\\",\" \\\n",
      "#    + \"      SPHEROID[\\\"WGS 84\\\",6378137,298.257223563,AUTHORITY[\\\"EPSG\\\",\\\"7030\\\"]],\" \\\n",
      "#    + \"      TOWGS84[0,0,0,0,0,0,0],\" \\\n",
      "#    + \"      AUTHORITY[\\\"EPSG\\\",\\\"6326\\\"]],\" \\\n",
      "#    + \"    PRIMEM[\\\"Greenwich\\\",0,AUTHORITY[\\\"EPSG\\\",\\\"8901\\\"]],\" \\\n",
      "#    + \"    UNIT[\\\"degree\\\",0.0174532925199433,AUTHORITY[\\\"EPSG\\\",\\\"9108\\\"]]],\" \\\n",
      "#    + \"  PROJECTION[\\\"Lambert Azimuthal Equal Area\\\",\" \\\n",
      "#    + \"    PARAMETER[\\\"Latitude of natural origin\\\",90,ANGLEUNIT[\\\"degree\\\",0.01745329252]],\" \\\n",
      "#    + \"    PARAMETER[\\\"Longitude of natural origin\\\",0,ANGLEUNIT[\\\"degree\\\",0.01745329252]],\" \\\n",
      "#    + \"    PARAMETER[\\\"False easting\\\",0,LENGTHUNIT[\\\"metre\\\",1.0]],\" \\\n",
      "#    + \"    PARAMETER[\\\"False northing\\\",0,LENGTHUNIT[\\\"metre\\\",1.0]]],\" \\\n",
      "#    + \"  UNIT[\\\"Meter\\\",1],\" \\\n",
      "#    + \"  AUTHORITY[\\\"EPSG\\\",\\\"6931\\\"]]\"\n",
      "#coords.GeoTransform = \"-9000000 100000 0 9000000 0 -100000 \""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#close the file to make sure everything is written\n",
      "d.close()\n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}